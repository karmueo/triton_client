#include <iostream>
#include <vector>
#include <string>
#include <memory>
#include <cmath>
#include <iomanip>
#include <fstream>
#include <random>
#include <chrono>
#include <algorithm>

#include "http_client.h"

namespace tc = triton::client;

class TritonClient {
public:
    TritonClient(const std::string& url = "localhost:8000", bool verbose = false) 
        : server_url_(url), verbose_(verbose) {
        // åˆ›å»ºHTTPå®¢æˆ·ç«¯
        tc::Error err = tc::InferenceServerHttpClient::Create(&client_, server_url_, verbose_);
        if (!err.IsOk()) {
            std::cerr << "âŒ åˆ›å»ºå®¢æˆ·ç«¯å¤±è´¥: " << err << std::endl;
            client_ = nullptr;
        }
    }

    ~TritonClient() {
        if (client_) {
            delete client_;
        }
    }

    bool CheckServerHealth() {
        if (!client_) {
            std::cerr << "âŒ å®¢æˆ·ç«¯æœªåˆå§‹åŒ–" << std::endl;
            return false;
        }

        bool live;
        tc::Error err = client_->IsServerLive(&live);
        if (!err.IsOk()) {
            std::cerr << "âŒ è¿æ¥æœåŠ¡å™¨å¤±è´¥: " << err << std::endl;
            return false;
        }

        if (live) {
            std::cout << "âœ… Triton æœåŠ¡å™¨è¿è¡Œæ­£å¸¸" << std::endl;
            return true;
        } else {
            std::cerr << "âŒ Triton æœåŠ¡å™¨æœªå“åº”" << std::endl;
            return false;
        }
    }

    bool GetModelInfo(const std::string& model_name) {
        if (!client_) return false;

        std::string model_metadata;
        tc::Error err = client_->ModelMetadata(&model_metadata, model_name);
        if (!err.IsOk()) {
            std::cerr << "âŒ è·å–æ¨¡å‹å…ƒæ•°æ®å¤±è´¥: " << err << std::endl;
            return false;
        }

        std::string model_config;
        err = client_->ModelConfig(&model_config, model_name);
        if (!err.IsOk()) {
            std::cerr << "âŒ è·å–æ¨¡å‹é…ç½®å¤±è´¥: " << err << std::endl;
            return false;
        }

        std::cout << "\nğŸ“‹ æ¨¡å‹ä¿¡æ¯: " << model_name << std::endl;
        std::cout << "å…ƒæ•°æ®: " << model_metadata << std::endl;
        std::cout << "é…ç½®: " << model_config << std::endl;

        return true;
    }

    bool ListModels() {
        if (!client_) return false;

        std::string repository_index;
        tc::Error err = client_->ModelRepositoryIndex(&repository_index);
        if (!err.IsOk()) {
            std::cerr << "âŒ è·å–æ¨¡å‹åˆ—è¡¨å¤±è´¥: " << err << std::endl;
            return false;
        }

        std::cout << "\nğŸ“¦ æ¨¡å‹ä»“åº“ä¿¡æ¯:" << std::endl;
        std::cout << repository_index << std::endl;

        return true;
    }

    std::vector<float> GenerateSampleData() {
        std::vector<float> data(20 * 14);
        
        // ä½¿ç”¨å›ºå®šç§å­ä»¥è·å¾—å¯é‡ç°çš„ç»“æœ
        std::mt19937 gen(42);
        std::normal_distribution<float> dist(0.0f, 1.0f);

        // ç”Ÿæˆéšæœºæ•°æ®
        for (int i = 0; i < 20; ++i) {
            for (int j = 0; j < 14; ++j) {
                float base_value = dist(gen);
                // æ·»åŠ æ­£å¼¦æ³¢æ¨¡å¼
                float pattern = std::sin(2.0f * M_PI * i / 20.0f) * (j + 1) * 0.1f;
                data[i * 14 + j] = base_value + pattern;
            }
        }

        return data;
    }

    std::vector<float> Softmax(const std::vector<float>& logits) {
        std::vector<float> result(logits.size());
        
        // æ‰¾åˆ°æœ€å¤§å€¼ä»¥æé«˜æ•°å€¼ç¨³å®šæ€§
        float max_val = *std::max_element(logits.begin(), logits.end());
        
        // è®¡ç®—expå’Œsum
        float sum = 0.0f;
        for (size_t i = 0; i < logits.size(); ++i) {
            result[i] = std::exp(logits[i] - max_val);
            sum += result[i];
        }
        
        // å½’ä¸€åŒ–
        for (size_t i = 0; i < result.size(); ++i) {
            result[i] /= sum;
        }
        
        return result;
    }

    bool PredictWithLabels(const std::string& model_name, 
                          const std::vector<float>& input_data,
                          const std::vector<std::string>& labels = {"bird", "uav"}) {
        if (!client_) return false;

        // è¾“å…¥æ•°æ®å½¢çŠ¶ [1, 20, 14]
        std::vector<int64_t> input_shape = {1, 20, 14};
        
        std::cout << "ğŸ“¥ è¾“å…¥æ•°æ®å½¢çŠ¶: [" << input_shape[0] << ", " 
                  << input_shape[1] << ", " << input_shape[2] << "]" << std::endl;
        std::cout << "ğŸ“¥ è¾“å…¥æ•°æ®å¤§å°: " << input_data.size() << std::endl;

        // å‡†å¤‡è¾“å…¥
        tc::InferInput* input;
        tc::Error err = tc::InferInput::Create(&input, "input", input_shape, "FP32");
        if (!err.IsOk()) {
            std::cerr << "âŒ åˆ›å»ºè¾“å…¥å¤±è´¥: " << err << std::endl;
            return false;
        }

        std::shared_ptr<tc::InferInput> input_ptr(input);

        // è®¾ç½®è¾“å…¥æ•°æ®
        err = input_ptr->AppendRaw(reinterpret_cast<const uint8_t*>(input_data.data()), 
                                   input_data.size() * sizeof(float));
        if (!err.IsOk()) {
            std::cerr << "âŒ è®¾ç½®è¾“å…¥æ•°æ®å¤±è´¥: " << err << std::endl;
            return false;
        }

        // å‡†å¤‡è¾“å‡º
        tc::InferRequestedOutput* output;
        err = tc::InferRequestedOutput::Create(&output, "output");
        if (!err.IsOk()) {
            std::cerr << "âŒ åˆ›å»ºè¾“å‡ºå¤±è´¥: " << err << std::endl;
            return false;
        }

        std::shared_ptr<tc::InferRequestedOutput> output_ptr(output);

        // æ‰§è¡Œæ¨ç†
        std::vector<tc::InferInput*> inputs = {input_ptr.get()};
        std::vector<const tc::InferRequestedOutput*> outputs = {output_ptr.get()};

        tc::InferResult* result;
        auto start_time = std::chrono::high_resolution_clock::now();
        
        err = client_->Infer(&result, model_name, inputs, outputs);
        
        auto end_time = std::chrono::high_resolution_clock::now();
        auto inference_time = std::chrono::duration_cast<std::chrono::microseconds>(end_time - start_time).count() / 1000.0;

        if (!err.IsOk()) {
            std::cerr << "âŒ æ¨ç†å¤±è´¥: " << err << std::endl;
            return false;
        }

        std::shared_ptr<tc::InferResult> result_ptr(result);

        std::cout << "âš¡ æ¨ç†æ—¶é—´: " << std::fixed << std::setprecision(4) 
                  << inference_time << " æ¯«ç§’" << std::endl;

        // è·å–è¾“å‡ºæ•°æ®
        const uint8_t* output_buffer;
        size_t output_byte_size;
        err = result_ptr->RawData("output", &output_buffer, &output_byte_size);
        if (!err.IsOk()) {
            std::cerr << "âŒ è·å–è¾“å‡ºæ•°æ®å¤±è´¥: " << err << std::endl;
            return false;
        }

        // è½¬æ¢è¾“å‡ºæ•°æ®
        const float* output_data = reinterpret_cast<const float*>(output_buffer);
        size_t output_size = output_byte_size / sizeof(float);

        std::vector<float> raw_output(output_data, output_data + output_size);
        
        std::cout << "ğŸ“¤ è¾“å‡ºå¤§å°: " << output_size << std::endl;
        std::cout << "ğŸ“¤ åŸå§‹è¾“å‡º: [";
        for (size_t i = 0; i < raw_output.size(); ++i) {
            std::cout << std::fixed << std::setprecision(4) << raw_output[i];
            if (i < raw_output.size() - 1) std::cout << ", ";
        }
        std::cout << "]" << std::endl;

        // è®¡ç®—softmaxæ¦‚ç‡
        std::vector<float> probabilities = Softmax(raw_output);

        // è·å–é¢„æµ‹ç»“æœ
        auto max_it = std::max_element(probabilities.begin(), probabilities.end());
        int predicted_class = std::distance(probabilities.begin(), max_it);
        float confidence = *max_it;

        std::string predicted_label = (predicted_class < labels.size()) ? 
                                     labels[predicted_class] : 
                                     "Class_" + std::to_string(predicted_class);

        // æ˜¾ç¤ºç»“æœ
        std::cout << "\nğŸ¯ é¢„æµ‹ç»“æœ:" << std::endl;
        std::cout << "é¢„æµ‹ç±»åˆ«: " << predicted_label << std::endl;
        std::cout << "ç½®ä¿¡åº¦: " << std::fixed << std::setprecision(4) << confidence << std::endl;
        std::cout << "æ¦‚ç‡åˆ†å¸ƒ: ";
        for (size_t i = 0; i < probabilities.size() && i < labels.size(); ++i) {
            std::cout << labels[i] << "=" << std::fixed << std::setprecision(4) 
                      << probabilities[i];
            if (i < std::min(probabilities.size(), labels.size()) - 1) {
                std::cout << ", ";
            }
        }
        std::cout << std::endl;

        return true;
    }

private:
    std::string server_url_;
    bool verbose_;
    tc::InferenceServerHttpClient* client_;
};

void PrintUsage(const char* program_name) {
    std::cout << "ç”¨æ³•: " << program_name << " [é€‰é¡¹]" << std::endl;
    std::cout << "é€‰é¡¹:" << std::endl;
    std::cout << "  --url URL          TritonæœåŠ¡å™¨åœ°å€ (é»˜è®¤: localhost:8000)" << std::endl;
    std::cout << "  --model MODEL      æ¨¡å‹åç§° (é»˜è®¤: Times_Classify)" << std::endl;
    std::cout << "  --verbose          å¯ç”¨è¯¦ç»†æ—¥å¿—" << std::endl;
    std::cout << "  --help             æ˜¾ç¤ºæ­¤å¸®åŠ©ä¿¡æ¯" << std::endl;
}

int main(int argc, char** argv) {
    std::string url = "localhost:8000";
    std::string model_name = "Times_Classify";
    bool verbose = false;

    // è§£æå‘½ä»¤è¡Œå‚æ•°
    for (int i = 1; i < argc; ++i) {
        std::string arg = argv[i];
        if (arg == "--help") {
            PrintUsage(argv[0]);
            return 0;
        } else if (arg == "--url" && i + 1 < argc) {
            url = argv[++i];
        } else if (arg == "--model" && i + 1 < argc) {
            model_name = argv[++i];
        } else if (arg == "--verbose") {
            verbose = true;
        } else {
            std::cerr << "æœªçŸ¥å‚æ•°: " << arg << std::endl;
            PrintUsage(argv[0]);
            return 1;
        }
    }

    std::cout << "ğŸš€ è¿æ¥åˆ° Triton æœåŠ¡å™¨: " << url << std::endl;

    // åˆ›å»ºå®¢æˆ·ç«¯
    TritonClient client(url, verbose);

    // æ£€æŸ¥æœåŠ¡å™¨å¥åº·çŠ¶æ€
    if (!client.CheckServerHealth()) {
        return 1;
    }

    // åˆ—å‡ºæ¨¡å‹
    client.ListModels();

    // è·å–æ¨¡å‹ä¿¡æ¯
    client.GetModelInfo(model_name);

    // ç”Ÿæˆç¤ºä¾‹æ•°æ®
    std::cout << "\nğŸ² ç”Ÿæˆç¤ºä¾‹æ•°æ®..." << std::endl;
    std::vector<float> data = client.GenerateSampleData();

    std::cout << "ğŸ“Š è¾“å…¥æ•°æ®å¤§å°: " << data.size() << std::endl;
    std::cout << "ğŸ“Š æ•°æ®èŒƒå›´: [" << std::fixed << std::setprecision(4) 
              << *std::min_element(data.begin(), data.end()) << ", "
              << *std::max_element(data.begin(), data.end()) << "]" << std::endl;

    // æ‰§è¡Œé¢„æµ‹
    std::cout << "\nğŸ”® å¼€å§‹æ¨ç†..." << std::endl;
    bool success = client.PredictWithLabels(model_name, data);

    if (success) {
        std::cout << "\nâœ… æ¨ç†å®Œæˆ!" << std::endl;
    } else {
        std::cerr << "\nâŒ æ¨ç†å¤±è´¥!" << std::endl;
        return 1;
    }

    return 0;
}
